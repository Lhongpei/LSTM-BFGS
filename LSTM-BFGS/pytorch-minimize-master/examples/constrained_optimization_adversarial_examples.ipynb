{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dried-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from torchmin import minimize_constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "whole-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "root = '/path/to/data'  # fill in torchvision dataset path\n",
    "train_data = datasets.MNIST(root, train=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-interview",
   "metadata": {},
   "source": [
    "# Train CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "following-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 10, kernel_size=5),\n",
    "        nn.SiLU(),\n",
    "        nn.AvgPool2d(2),\n",
    "        nn.Conv2d(10, 20, kernel_size=5),\n",
    "        nn.SiLU(),\n",
    "        nn.AvgPool2d(2),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Flatten(1),\n",
    "        nn.Linear(320, 50),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(50, 10),\n",
    "        nn.LogSoftmax(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accessory-killer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 - loss: 0.4923\n",
      "epoch  2 - loss: 0.1428\n",
      "epoch  3 - loss: 0.1048\n",
      "epoch  4 - loss: 0.0883\n",
      "epoch  5 - loss: 0.0754\n",
      "epoch  6 - loss: 0.0672\n",
      "epoch  7 - loss: 0.0626\n",
      "epoch  8 - loss: 0.0578\n",
      "epoch  9 - loss: 0.0524\n",
      "epoch 10 - loss: 0.0509\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(382)\n",
    "net = CNN().to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    for (x, y) in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = net(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * x.size(0)\n",
    "    print('epoch %2d - loss: %0.4f' % (epoch+1, epoch_loss / len(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-elimination",
   "metadata": {},
   "source": [
    "# set up adversarial example environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developing-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation mode settings\n",
    "net = net.requires_grad_(False).eval()\n",
    "\n",
    "# move net to CPU\n",
    "# Note: using CUDA-based inputs and objectives is allowed\n",
    "# but inefficient with trust-constr, as the data will be\n",
    "# moved back-and-forth from CPU\n",
    "net = net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mighty-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_objective(x, y):\n",
    "    assert x.numel() == 28**2\n",
    "    assert y.numel() == 1\n",
    "    x = x.view(1, 1, 28, 28)\n",
    "    return F.nll_loss(net(x), y.view(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "better-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random image from the dataset\n",
    "torch.manual_seed(338)\n",
    "x, y = next(iter(train_loader))\n",
    "img = x[0]\n",
    "label = y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "presidential-astrology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4663e-05)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_objective(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "independent-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimization objective for adversarial examples\n",
    "#   goal is to maximize NLL of perturbed image (image + perturbation)\n",
    "fn = lambda eps: - nll_objective(img + eps, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacterial-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting utility\n",
    "\n",
    "def plot_distortion(img, eps, y):\n",
    "    assert img.numel() == 28**2\n",
    "    assert eps.numel() == 28**2\n",
    "    img = img.view(28, 28)\n",
    "    img_ = img + eps.view(28, 28)\n",
    "    fig, axes = plt.subplots(1,2,figsize=(4,2))\n",
    "    for i, x in enumerate((img, img_)):\n",
    "        axes[i].imshow(x.cpu(), cmap=plt.cm.binary)\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "        axes[i].set_title('nll: %0.4f' % nll_objective(x, y))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-thread",
   "metadata": {},
   "source": [
    "# craft adversarial example\n",
    "\n",
    "We will use our constrained optimizer to find the optimal unit-norm purturbation $\\epsilon$ \n",
    "\n",
    "\\begin{equation}\n",
    "\\max_{\\epsilon} NLL(x + \\epsilon) \\quad \\text{s.t.} \\quad ||\\epsilon|| = 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "surprised-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(227)\n",
    "eps0 = torch.randn_like(img)\n",
    "eps0 /= eps0.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "missing-bargain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2291887944447808e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(eps0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "miniature-fight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 32, function evaluations: 50, CG iterations: 52, optimality: 1.02e-04, constraint violation: 0.00e+00, execution time: 0.57 s.\n"
     ]
    }
   ],
   "source": [
    "res = minimize_constr(\n",
    "    fn, eps0, \n",
    "    max_iter=100,\n",
    "    constr=dict(\n",
    "        fun=lambda x: x.square().sum(), \n",
    "        lb=1, ub=1\n",
    "    ),\n",
    "    disp=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wanted-journal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "eps = res.x\n",
    "print(eps.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spanish-wright",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distortion(img.detach(), eps, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-commission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}